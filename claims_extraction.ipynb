{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import tiktoken\n",
    "from openai import AzureOpenAI"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def extract_infos(json_file_path) -> dict:\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "\n",
    "def init_client(infos: dict):\n",
    "    client = AzureOpenAI(\n",
    "    azure_endpoint = infos['azure_endpoint'],\n",
    "    api_key = infos['api_key'],\n",
    "    api_version = infos['api_version']\n",
    "    )\n",
    "\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "\n",
    "    return num_tokens\n",
    "\n",
    "def message(role, content) -> dict:\n",
    "    return {\"role\": role, \"content\": content}\n",
    "\n",
    "def read_file(absolute_path):\n",
    "    with open(absolute_path) as file:\n",
    "        return file.read()\n",
    "\n",
    "def load_tables_from_json(json_file):\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def check_processed_tables(json_file_path: str, tables_directory_path: str):\n",
    "    data = load_tables_from_json(json_file_path)\n",
    "\n",
    "    for file_name in os.listdir(tables_directory_path):\n",
    "        if file_name.endswith('.txt'):\n",
    "            parts = file_name.split('_')\n",
    "            if len(parts) == 2:\n",
    "                article_id = parts[0]\n",
    "                table_index = int(parts[1].split('.')[0])\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            if article_id in data:\n",
    "                article = data[article_id]\n",
    "                if 0 <= table_index < len(article):\n",
    "                    article[table_index]['processed'] = True\n",
    "\n",
    "    with open(json_file_path, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "def build_messages(file_name, messages_file_path, html_table, output_prompts_folder):\n",
    "    content_system_1 = read_file(messages_file_path['system_1'])\n",
    "    content_user_1 = read_file(messages_file_path['user_1'])\n",
    "    content_assistant = read_file(messages_file_path['assistant'])\n",
    "    content_user_2 = read_file(messages_file_path['user_2']) + '\\n\\n' + html_table\n",
    "    content_system_2 = read_file(messages_file_path['system_2'])\n",
    "\n",
    "    messages_dict = [\n",
    "        message(\"system\", content_system_1),\n",
    "        message(\"user\", content_user_1),\n",
    "        message(\"assistant\", content_assistant),\n",
    "        message(\"user\", content_user_2),\n",
    "        message(\"system\", content_system_2)\n",
    "    ]\n",
    "\n",
    "    # save prompt for replication purposes\n",
    "    file_name_txt = file_name + '.txt'\n",
    "    with open(os.path.join(output_prompts_folder, file_name_txt), \"w\") as text_file:\n",
    "        text_file.write(json.dumps(messages_dict))\n",
    "    print(f\"\\t Saved prompt at: {os.path.join(output_prompts_folder, file_name_txt)}\")\n",
    "\n",
    "    # number of input tokens\n",
    "    input_tokens = num_tokens_from_string(content_system_1 + content_user_1 + content_assistant + content_user_2 + content_system_2)\n",
    "\n",
    "    return messages_dict, input_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def send_request(client, prompt: dict, max_tokens = 16000):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    with client.chat.completions.with_streaming_response.create(\n",
    "        model=\"gpt-4-32k\", # model = \"deployment_name\".\n",
    "        max_tokens = 6000,\n",
    "        temperature = 0,\n",
    "        stream=True,\n",
    "        messages = prompt,\n",
    "    ) as response:\n",
    "        #Â print(response.headers.get(\"X-My-Header\"))\n",
    "        answer = ''\n",
    "        current_answer = ''\n",
    "        output_tokens = 0\n",
    "        stream = ''\n",
    "\n",
    "        for line in response.iter_lines():\n",
    "\n",
    "            stream += line + '\\n'\n",
    "\n",
    "            if len(line) > 0:\n",
    "                output_tokens += 1\n",
    "                line = line.replace('data: ', '')\n",
    "                if line == '[DONE]':\n",
    "                    break\n",
    "                json_line = json.loads(line)\n",
    "                if len(json_line['choices']) > 0 and  json_line['choices'][0] != None and json_line['choices'][0]['delta'] != None and len(json_line['choices'][0]['delta']) > 0 and json_line['choices'][0]['delta']['content'] != None:\n",
    "                    current_token = json_line['choices'][0]['delta']['content']\n",
    "                    # answer += json_line['choices'][0]['delta']['content']\n",
    "                    answer += current_token\n",
    "                    current_answer += current_token\n",
    "                    if '\\n' in current_token:\n",
    "                        print(current_answer)\n",
    "                        current_answer = ''\n",
    "    request_time = time.time() - start_time\n",
    "\n",
    "    return answer, output_tokens, request_time, stream\n",
    "\n",
    "def save_answer_and_stats(answer, input_tokens, output_tokens, request_time, stream, file_name, output_answers_folder):\n",
    "    file_name_txt = file_name + '.txt'\n",
    "    with open(os.path.join(output_answers_folder, file_name_txt), \"w\") as text_file:\n",
    "        text_file.write(answer.encode('ascii', 'ignore').decode())\n",
    "    print(f\"\\t Saved answer at: {os.path.join(output_answers_folder, file_name_txt)}\")\n",
    "\n",
    "    '''\n",
    "    data_dict = {\"file_name\": file_name, \"input_tokens\": input_tokens, \"output_tokens\": output_tokens, \"request_time\": request_time, \"stream\": stream}\n",
    "    print(data_dict)\n",
    "    df = pd.DataFrame([data_dict])\n",
    "    with pd.ExcelWriter(os.path.join(output_stats_folder, stats_file), engine='openpyxl', if_sheet_exists=\"overlay\", mode='a') as writer:\n",
    "        df.to_excel(writer, sheet_name='main', startrow=writer.sheets['main'].max_row, index=False, header=False)\n",
    "\n",
    "    print(f\"\\t Saved stats at: {os.path.join(output_stats_folder, stats_file)}\")\n",
    "    '''\n",
    "\n",
    "    return\n",
    "\n",
    "def run(connection_data: dict, messages_file_paths: dict, articles_tables: dict, output_prompts_folder, output_answers_folder):\n",
    "\n",
    "    client = init_client(connection_data)\n",
    "\n",
    "    for article_id, article_tables in articles_tables.items():\n",
    "        for index, article_table in enumerate(article_tables):\n",
    "            if article_table['processed']:\n",
    "                continue\n",
    "\n",
    "            table_html = article_table['table'].encode('ascii', 'ignore').decode()\n",
    "            file_name = f\"{article_id}_{index}\"\n",
    "\n",
    "            prompt, input_tokens = build_messages(file_name, messages_file_paths, table_html, output_prompts_folder)\n",
    "            print(f\"Sending request for: [{article_id} - T{index + 1}]\")\n",
    "            answer, output_tokens, request_time, stream = send_request(client, prompt)\n",
    "\n",
    "            save_answer_and_stats(answer, input_tokens, output_tokens, request_time, stream, file_name, output_answers_folder)\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "connection_infos = extract_infos('private.json')\n",
    "\n",
    "answers_folder = 'experiments/answers/nba'\n",
    "prompts_folder = 'experiments/prompts/nba'\n",
    "\n",
    "msgs_base_path = 'experiments/messages/ER'\n",
    "\n",
    "msgs_file_paths = {\n",
    "    'system_1':  f'{msgs_base_path}/system_1.txt',\n",
    "    'system_2':  f'{msgs_base_path}/system_2.txt',\n",
    "    'user_1':    f'{msgs_base_path}/user_1.txt',\n",
    "    'user_2':    f'{msgs_base_path}/user_2.txt',\n",
    "    'assistant': f'{msgs_base_path}/assistant.txt'\n",
    "}\n",
    "\n",
    "tables_file_path = 'experiments/extracted_tables/nba.json'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "tables = load_tables_from_json(tables_file_path)\n",
    "\n",
    "check_processed_tables(tables_file_path, answers_folder)\n",
    "\n",
    "run(connection_infos, msgs_file_paths, tables, prompts_folder, answers_folder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}