{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import tiktoken\n",
    "from openai import AzureOpenAI\n",
    "from requests.exceptions import ReadTimeout\n",
    "import concurrent.futures"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def extract_infos(json_file_path) -> dict:\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "\n",
    "def init_client(infos: dict):\n",
    "    client = AzureOpenAI(\n",
    "    azure_endpoint = infos['azure_endpoint'],\n",
    "    api_key = infos['api_key'],\n",
    "    api_version = infos['api_version']\n",
    "    )\n",
    "\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "\n",
    "    return num_tokens\n",
    "\n",
    "def message(role, content) -> dict:\n",
    "    return {\"role\": role, \"content\": content}\n",
    "\n",
    "def read_file(absolute_path):\n",
    "    with open(absolute_path) as file:\n",
    "        return file.read()\n",
    "\n",
    "def load_tables_from_json(json_file):\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def check_processed_tables(json_file_path: str, tables_directory_path: str):\n",
    "    data = load_tables_from_json(json_file_path)\n",
    "\n",
    "    for file_name in os.listdir(tables_directory_path):\n",
    "        if file_name.endswith('.txt'):\n",
    "            parts = file_name.split('_')\n",
    "            if len(parts) == 2:\n",
    "                article_id = parts[0]\n",
    "                table_index = int(parts[1].split('.')[0])\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            if article_id in data:\n",
    "                article = data[article_id]\n",
    "                if 0 <= table_index < len(article):\n",
    "                    article[table_index]['processed'] = True\n",
    "\n",
    "    with open(json_file_path, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "def build_messages(file_name, messages_file_path, html_table, output_prompts_folder):\n",
    "    content_system_1 = read_file(messages_file_path['system_1'])\n",
    "    content_user_1 = read_file(messages_file_path['user_1'])\n",
    "    content_assistant = read_file(messages_file_path['assistant'])\n",
    "    content_user_2 = read_file(messages_file_path['user_2']) + '\\n' + html_table\n",
    "    content_system_2 = read_file(messages_file_path['system_2'])\n",
    "\n",
    "    messages_dict = [\n",
    "        message(\"system\", content_system_1),\n",
    "        message(\"user\", content_user_1),\n",
    "        message(\"assistant\", content_assistant),\n",
    "        message(\"user\", content_user_2),\n",
    "        message(\"system\", content_system_2)\n",
    "    ]\n",
    "\n",
    "    # save prompt for replication purposes\n",
    "    file_name_txt = file_name + '.txt'\n",
    "    with open(os.path.join(output_prompts_folder, file_name_txt), \"w\") as text_file:\n",
    "        text_file.write(json.dumps(messages_dict))\n",
    "    print(f\"\\t Saved prompt at: {os.path.join(output_prompts_folder, file_name_txt)}\")\n",
    "\n",
    "    # number of input tokens\n",
    "    input_tokens = num_tokens_from_string(content_system_1 + content_user_1 + content_assistant + content_user_2 + content_system_2)\n",
    "\n",
    "    return messages_dict, input_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def send_request(client, prompt: dict, max_tokens = 16000):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    with client.chat.completions.with_streaming_response.create(\n",
    "        model=\"gpt-4-32k\", # model = \"deployment_name\".\n",
    "        max_tokens = 6000,\n",
    "        temperature = 0,\n",
    "        stream=True,\n",
    "        messages = prompt,\n",
    "    ) as response:\n",
    "        #Â print(response.headers.get(\"X-My-Header\"))\n",
    "        answer = ''\n",
    "        current_answer = ''\n",
    "        output_tokens = 0\n",
    "        stream = ''\n",
    "\n",
    "        for line in response.iter_lines():\n",
    "\n",
    "            stream += line + '\\n'\n",
    "\n",
    "            if len(line) > 0:\n",
    "                output_tokens += 1\n",
    "                line = line.replace('data: ', '')\n",
    "                if line == '[DONE]':\n",
    "                    break\n",
    "                json_line = json.loads(line)\n",
    "                if len(json_line['choices']) > 0 and  json_line['choices'][0] != None and json_line['choices'][0]['delta'] != None and len(json_line['choices'][0]['delta']) > 0 and json_line['choices'][0]['delta']['content'] != None:\n",
    "                    current_token = json_line['choices'][0]['delta']['content']\n",
    "                    # answer += json_line['choices'][0]['delta']['content']\n",
    "                    answer += current_token\n",
    "                    current_answer += current_token\n",
    "                    if '\\n' in current_token:\n",
    "                        print(current_answer)\n",
    "                        current_answer = ''\n",
    "    request_time = time.time() - start_time\n",
    "\n",
    "    return answer, output_tokens, request_time, stream\n",
    "\n",
    "def save_answer_and_stats(answer, input_tokens, output_tokens, request_time, stream, file_name, output_answers_folder):\n",
    "    file_name_txt = file_name + '.txt'\n",
    "    with open(os.path.join(output_answers_folder, file_name_txt), \"w\") as text_file:\n",
    "        text_file.write(answer.encode('ascii', 'ignore').decode())\n",
    "    print(f\"\\t Saved answer at: {os.path.join(output_answers_folder, file_name_txt)}\")\n",
    "\n",
    "    '''\n",
    "    data_dict = {\"file_name\": file_name, \"input_tokens\": input_tokens, \"output_tokens\": output_tokens, \"request_time\": request_time, \"stream\": stream}\n",
    "    print(data_dict)\n",
    "    df = pd.DataFrame([data_dict])\n",
    "    with pd.ExcelWriter(os.path.join(output_stats_folder, stats_file), engine='openpyxl', if_sheet_exists=\"overlay\", mode='a') as writer:\n",
    "        df.to_excel(writer, sheet_name='main', startrow=writer.sheets['main'].max_row, index=False, header=False)\n",
    "\n",
    "    print(f\"\\t Saved stats at: {os.path.join(output_stats_folder, stats_file)}\")\n",
    "    '''\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def extract_claims(client, article_table, file_name, messages_file_paths, output_prompts_folder, output_answers_folder):\n",
    "    table_html = article_table['table'].encode('ascii', 'ignore').decode()\n",
    "\n",
    "    prompt, input_tokens = build_messages(file_name, messages_file_paths, table_html, output_prompts_folder)\n",
    "    print(f\"Sending request for: [{file_name}]\")\n",
    "\n",
    "    for attempt in range(2):\n",
    "        try:\n",
    "            answer, output_tokens, request_time, stream = send_request(client, prompt)\n",
    "            break\n",
    "        except ReadTimeout:\n",
    "            print(f\"ReadTimeout occurred. Retrying... Attempt\")\n",
    "    else:\n",
    "        print(\"All retry attempts failed. Handle the error or raise it again.\")\n",
    "        return\n",
    "\n",
    "    save_answer_and_stats(answer, input_tokens, output_tokens, request_time, stream, file_name, output_answers_folder)\n",
    "\n",
    "\n",
    "def run(connection_data: dict, messages_file_paths: dict, articles_tables: dict, output_prompts_folder, output_answers_folder, num_threads):\n",
    "    clients = [init_client(connection_data) for _ in range(num_threads)]\n",
    "\n",
    "    progress = 0\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        for article_id, article_tables in articles_tables.items():\n",
    "            for index, article_table in enumerate(article_tables):\n",
    "                if article_table['processed']:\n",
    "                    continue\n",
    "\n",
    "                executor.submit(\n",
    "                    extract_claims,\n",
    "                    clients[progress % num_threads],\n",
    "                    article_table,\n",
    "                    f\"{article_id}_{index}\",\n",
    "                    messages_file_paths,\n",
    "                    output_prompts_folder,\n",
    "                    output_answers_folder\n",
    "                )\n",
    "\n",
    "                progress += 1\n",
    "\n",
    "    for client in clients:\n",
    "        client.close()\n",
    "\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def check_path(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "connection_infos = extract_infos('private.json')\n",
    "\n",
    "msgs_base_path = 'messages/CS'\n",
    "\n",
    "msgs_file_paths = {\n",
    "    'system_1':  f'{msgs_base_path}/system_1.txt',\n",
    "    'system_2':  f'{msgs_base_path}/system_2.txt',\n",
    "    'user_1':    f'{msgs_base_path}/user_1.txt',\n",
    "    'user_2':    f'{msgs_base_path}/user_2.txt',\n",
    "    'assistant': f'{msgs_base_path}/assistant.txt'\n",
    "}\n",
    "\n",
    "answers_folder = 'experiments/answers/test/13'\n",
    "prompts_folder = 'experiments/prompts/test/13'\n",
    "\n",
    "check_path(answers_folder)\n",
    "check_path(prompts_folder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Saved prompt at: experiments/prompts/test/12\\2301.04770_0.txt\n",
      "\t Saved prompt at: experiments/prompts/test/12\\2301.04770_1.txt\n",
      "\t Saved prompt at: experiments/prompts/test/12\\2307.01231_2.txt\n",
      "\t Saved prompt at: experiments/prompts/test/12\\2307.01231_5.txt\n",
      "\t Saved prompt at: experiments/prompts/test/12\\2301.02962_1.txt\n",
      "Sending request for: [2301.04770_1]\n",
      "Sending request for: [2301.04770_0]Sending request for: [2307.01231_5]Sending request for: [2307.01231_2]\n",
      "\n",
      "\n",
      "Sending request for: [2301.02962_1]\n",
      "<{<Models, RoBERTa>, <Dataset, DBLP>}, F1 Score, 95.81>\n",
      "\n",
      "<{<Models, RoBERTa>, <Dataset, iTunes>}, F1 Score, 72.73>\n",
      "\n",
      "<{<Data Type, Structured>, <Dataset, Amazon-Google>, <Domain, software>, <Size, 11,460>, <# Positive, 1,167>, <# Attr., 3>}>\n",
      "\n",
      "<{<Data set, RLdata>, <EPregime, PY>}, Precision, 0.896>\n",
      "\n",
      "<{<Data set, RLdata>, <EPregime, PY>}, Recall, 0.961>\n",
      "\n",
      "<{<Models, RoBERTa>, <Dataset, Amazon>}, F1 Score, 61.76>\n",
      "\n",
      "<{<Models, RoBERTa>, <Dataset, Google>}, F1 Score, 73.12>\n",
      "\n",
      "<{<Models, RoBERTa>, <Dataset, ACM>}, F1 Score, 98.77>\n",
      "\n",
      "<{<Data Type, Structured>, <Dataset, iTunes-Amazon>, <Domain, music>, <Size, 539>, <# Positive, 132>, <# Attr., 8>}>\n",
      "\n",
      "<{<Data set, RLdata>, <EPregime, PY>}, F1 score, 0.928>\n",
      "\n",
      "<{<Data set, RLdata>, <EPregime, Ewens>}, Precision, 0.870>\n",
      "\n",
      "<{<Data set, RLdata>, <EPregime, Ewens>}, Recall, 0.970>\n",
      "\n",
      "<{<Dataset1, Abt>, <Dataset2, Buy>, <|D1|, 1076>, <|D2|, 1076>, <|A|, 3>, <attr., name>, <cl., x>, <K, 31>, <ind., D2>, <|Itr|, 20014>, <|Ite|, 6671>, <|Ptr|, 580>, <|Pte|, 193>, <|Ntr|, 19433>, <|Nte|, 6478>, <IR, 2.9%>}, PC, 0.899>\n",
      "\n",
      "<{<Data Type, Structured>, <Dataset, DBLP-ACM>, <Domain, citation>, <Size, 12,363>, <# Positive, 2,220>, <# Attr., 4>}>\n",
      "\n",
      "<{<Models, RoBERTa>, <Dataset, GoogleScholar>}, F1 Score, 95.32>\n",
      "\n",
      "<{<Models, RoBERTa>, <Dataset, Buy>}, F1 Score, 88.41>\n",
      "\n",
      "<{<Data set, RLdata>, <EPregime, Ewens>}, F1 score, 0.917>\n",
      "\n",
      "<{<Data set, RLdata>, <EPregime, GenCoupon>}, Precision, 0.903>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# output_stats_folder = 'stats/ER/'\n",
    "# stats_file = 'stats_1.xlsx'\n",
    "\n",
    "tables_file_path = 'experiments/extracted_tables/extraction_test.json'\n",
    "\n",
    "tables = load_tables_from_json(tables_file_path)\n",
    "check_processed_tables(tables_file_path, answers_folder)\n",
    "run(connection_infos, msgs_file_paths, tables, prompts_folder, answers_folder, 5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}